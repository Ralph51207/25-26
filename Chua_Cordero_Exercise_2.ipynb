{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "08d1026c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Dense_Layer:\n",
    "    def __init__(self, n_inputs, n_neurons, activation=\"linear\"):\n",
    "        self.n_inputs = n_inputs\n",
    "        self.n_neurons = n_neurons\n",
    "        self.activation_name = activation.lower()\n",
    "        self.weights = np.zeros((n_inputs, n_neurons))\n",
    "        self.biases = np.zeros((1, n_neurons))\n",
    "        self.inputs = None\n",
    "        self.z = None\n",
    "        self.a = None\n",
    "\n",
    "    def set_inputs_weights(self, inputs, weights=None, biases=None):\n",
    "        self.inputs = np.array(inputs, dtype=float).reshape(1, -1)\n",
    "        if weights is not None:\n",
    "            self.weights = np.array(weights, dtype=float).reshape(self.n_inputs, self.n_neurons)\n",
    "        if biases is not None:\n",
    "            self.biases = np.array(biases, dtype=float).reshape(1, self.n_neurons)\n",
    "\n",
    "    def weighted_sum(self):\n",
    "        self.z = self.inputs.dot(self.weights) + self.biases\n",
    "        return self.z\n",
    "\n",
    "    def activate(self):\n",
    "        if self.activation_name == \"relu\":\n",
    "            self.a = np.maximum(0, self.z)\n",
    "        elif self.activation_name == \"sigmoid\":\n",
    "            self.a = 1 / (1 + np.exp(-self.z))\n",
    "        elif self.activation_name == \"softmax\":\n",
    "            z_stable = self.z - np.max(self.z, axis=1, keepdims=True)\n",
    "            exp_z = np.exp(z_stable)\n",
    "            self.a = exp_z / np.sum(exp_z, axis=1, keepdims=True)\n",
    "        else:\n",
    "            self.a = self.z\n",
    "        return self.a\n",
    "\n",
    "    def forward(self, inputs=None):\n",
    "        if inputs is not None:\n",
    "            self.inputs = np.array(inputs, dtype=float).reshape(1, -1)\n",
    "        z = self.weighted_sum()\n",
    "        a = self.activate()\n",
    "        return z, a\n",
    "\n",
    "    @staticmethod\n",
    "    def loss(y_pred, y_true):\n",
    "        y_pred = np.array(y_pred, dtype=float)\n",
    "        y_true = np.array(y_true, dtype=float)\n",
    "        if y_pred.ndim == 1:\n",
    "            y_pred = y_pred.reshape(1, -1)\n",
    "        if y_true.ndim == 1:\n",
    "            y_true = y_true.reshape(1, -1)\n",
    "        epsilon = 1e-15\n",
    "        y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
    "        if y_pred.shape[1] == 1:\n",
    "            return -np.sum(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred)) / y_true.shape[0]\n",
    "        else:\n",
    "            return -np.sum(y_true * np.log(y_pred)) / y_true.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cea73f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== IRIS DATASET ===\n",
      "=== FIRST HIDDEN LAYER ===\n",
      "Weighted Sum: [3.93 0.15 0.85]\n",
      "After ReLU: [3.93 0.15 0.85]\n",
      "\n",
      "=== SECOND HIDDEN LAYER ===\n",
      "Weighted Sum: [5.074 4.805]\n",
      "After Sigmoid: [0.99378157 0.99187781]\n",
      "\n",
      "=== THIRD HIDDEN LAYER ===\n",
      "Weighted Sum: [-1.20148478  2.39699221 -2.90172587]\n",
      "After Softmax: [0.0265075  0.96865119 0.00484132]\n",
      "\n",
      "Hidden Layer 2 (Output) Loss: 3.080656405230887\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1) Iris Dataset Example\n",
    "\n",
    "print(\"=== IRIS DATASET ===\")\n",
    "\n",
    "X_iris = [5.1, 3.5, 1.4, 0.2]\n",
    "target_iris = [0.7, 0.2, 0.1]\n",
    "\n",
    "# Layer 1\n",
    "W1_iris = [[0.2, 0.5, -0.3],\n",
    "           [0.1, -0.2, 0.4],\n",
    "           [-0.4, 0.3, 0.2],\n",
    "           [0.6, -0.1, 0.5]]\n",
    "B1_iris = [3.0, -2.1, 0.6]\n",
    "layer1_iris = Dense_Layer(4, 3, 'relu')\n",
    "layer1_iris.set_inputs_weights(X_iris, W1_iris, B1_iris)\n",
    "z1, a1 = layer1_iris.forward()\n",
    "print(\"=== FIRST HIDDEN LAYER ===\")\n",
    "print(\"Weighted Sum:\", z1.flatten())\n",
    "print(\"After ReLU:\", a1.flatten())\n",
    "\n",
    "# Layer 2\n",
    "W2_iris = [[0.3, -0.5],\n",
    "           [0.7, 0.2],\n",
    "           [-0.6, 0.4]]\n",
    "B2_iris = [4.3, 6.4]\n",
    "layer2_iris = Dense_Layer(3, 2, 'sigmoid')\n",
    "layer2_iris.set_inputs_weights(a1, W2_iris, B2_iris)\n",
    "z2, a2 = layer2_iris.forward()\n",
    "print(\"\\n=== SECOND HIDDEN LAYER ===\")\n",
    "print(\"Weighted Sum:\", z2.flatten())\n",
    "print(\"After Sigmoid:\", a2.flatten())\n",
    "\n",
    "# Layer 3\n",
    "W3_iris = [[0.5, -0.3, 0.8],\n",
    "           [-0.2, 0.6, -0.4]]\n",
    "B3_iris = [-1.5, 2.1, -3.3]\n",
    "layer3_iris = Dense_Layer(2, 3, 'softmax')\n",
    "layer3_iris.set_inputs_weights(a2, W3_iris, B3_iris)\n",
    "z3, a3 = layer3_iris.forward()\n",
    "print(\"\\n=== THIRD HIDDEN LAYER ===\")\n",
    "print(\"Weighted Sum:\", z3.flatten())\n",
    "print(\"After Softmax:\", a3.flatten())\n",
    "\n",
    "loss_iris = Dense_Layer.loss(a3, target_iris)\n",
    "print(\"\\nHidden Layer 2 (Output) Loss:\", loss_iris)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "74575336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== BREAST CANCER DATASET ===\n",
      "=== FIRST HIDDEN LAYER ===\n",
      "Weighted Sum: [11.3435  3.4755 -0.2905]\n",
      "After ReLU: [11.3435  3.4755  0.    ]\n",
      "\n",
      "=== SECOND HIDDEN LAYER ===\n",
      "Weighted Sum: [ 8.2963  -4.11135]\n",
      "After Sigmoid: [0.99975062 0.01612148]\n",
      "\n",
      "=== THIRD HIDDEN LAYER ===\n",
      "Weighted Sum: [0.8917647]\n",
      "After Sigmoid: [0.70925421]\n",
      "\n",
      "Hidden Layer 2 (Output) Loss: 0.343541269530652\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 2) Breast Cancer Dataset Example\n",
    "\n",
    "print(\"\\n=== BREAST CANCER DATASET ===\")\n",
    "\n",
    "X_cancer = [14.1, 20.3, 0.095]\n",
    "target_cancer = [1]\n",
    "\n",
    "# Layer 1\n",
    "W1_c = [[0.5, -0.3, 0.8],\n",
    "        [0.2, 0.4, -0.6],\n",
    "        [-0.7, 0.9, 0.1]]\n",
    "B1_c = [0.3, -0.5, 0.6]\n",
    "layer1_c = Dense_Layer(3, 3, 'relu')\n",
    "layer1_c.set_inputs_weights(X_cancer, W1_c, B1_c)\n",
    "z1_c, a1_c = layer1_c.forward()\n",
    "print(\"=== FIRST HIDDEN LAYER ===\")\n",
    "print(\"Weighted Sum:\", z1_c.flatten())\n",
    "print(\"After ReLU:\", a1_c.flatten())\n",
    "\n",
    "# Layer 2\n",
    "W2_c = [[0.6, -0.2],\n",
    "        [0.4, -0.3],\n",
    "        [0.5, 0.7]]\n",
    "B2_c = [0.1, -0.8]\n",
    "layer2_c = Dense_Layer(3, 2, 'sigmoid')\n",
    "layer2_c.set_inputs_weights(a1_c, W2_c, B2_c)\n",
    "z2_c, a2_c = layer2_c.forward()\n",
    "print(\"\\n=== SECOND HIDDEN LAYER ===\")\n",
    "print(\"Weighted Sum:\", z2_c.flatten())\n",
    "print(\"After Sigmoid:\", a2_c.flatten())\n",
    "\n",
    "# Layer 3\n",
    "W3_c = [[0.7],\n",
    "        [-0.5]]\n",
    "B3_c = [0.2]\n",
    "layer3_c = Dense_Layer(2, 1, 'sigmoid')\n",
    "layer3_c.set_inputs_weights(a2_c, W3_c, B3_c)\n",
    "z3_c, a3_c = layer3_c.forward()\n",
    "print(\"\\n=== THIRD HIDDEN LAYER ===\")\n",
    "print(\"Weighted Sum:\", z3_c.flatten())\n",
    "print(\"After Sigmoid:\", a3_c.flatten())\n",
    "\n",
    "loss_cancer = Dense_Layer.loss(a3_c, target_cancer)\n",
    "print(\"\\nHidden Layer 2 (Output) Loss:\", loss_cancer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
